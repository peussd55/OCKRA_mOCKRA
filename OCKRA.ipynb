{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# OCKRA 모델 정의\n",
    "class OCKRA(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_classifiers=100, n_clusters=10, subsample_ratio=0.63):\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.n_clusters = n_clusters\n",
    "        self.subsample_ratio = subsample_ratio\n",
    "        self.ensemble_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input X must be a Pandas DataFrame.\")\n",
    "        \n",
    "        self.ensemble_ = []\n",
    "        for _ in range(self.n_classifiers):\n",
    "            random_features = np.random.choice(X.columns, size=int(len(X.columns) * self.subsample_ratio), replace=False)\n",
    "            X_subset = X[random_features]\n",
    "            kmeans = KMeans(n_clusters=self.n_clusters, init='k-means++', n_init=10, random_state=42).fit(X_subset)\n",
    "            self.ensemble_.append((kmeans, random_features))\n",
    "        return self\n",
    "\n",
    "    def reconstruction_error(self, X):\n",
    "        if not self.ensemble_:\n",
    "            raise ValueError(\"Model is not fitted yet. Please call fit() before reconstruction_error().\")\n",
    "\n",
    "        total_similarity = np.zeros(len(X))  # 총 유사도 점수 초기화\n",
    "        \n",
    "        for kmeans, features in self.ensemble_:\n",
    "            X_subset = X[features]\n",
    "            distances = kmeans.transform(X_subset).min(axis=1)\n",
    "            delta_i = np.mean(distances)  # 평균 거리 δi\n",
    "            similarity = self.similarity_score(distances, delta_i)\n",
    "            total_similarity += similarity\n",
    "        \n",
    "        total_similarity /= self.n_classifiers  # 앙상블 평균 유사도\n",
    "        return total_similarity\n",
    "\n",
    "    \n",
    "    def similarity_score(self, distances, delta_i):\n",
    "        \"\"\"\n",
    "        거리값을 기반으로 유사도 점수를 계산합니다.\n",
    "        \n",
    "        Args:\n",
    "            distances (array): 클러스터 중심과의 거리값들\n",
    "            delta_i (float): 평균 거리 δi\n",
    "            \n",
    "        Returns:\n",
    "            array: 0~1 범위의 유사도 점수\n",
    "        \"\"\"\n",
    "        scores = np.ones(len(distances))  # 기본값 1 (최대 유사도)\n",
    "        # δi 이하 → 점수 0.6 초과\n",
    "        scores[distances <= delta_i] = 0.6 + 0.4 * (1 - (distances[distances <= delta_i] / delta_i))\n",
    "        \n",
    "        # δi의 3배 이상 → 점수 0.02 이하\n",
    "        scores[distances >= 3 * delta_i] = 0.02\n",
    "        \n",
    "        # 중간값 → 점수는 선형적으로 조정됨\n",
    "        mask = (distances > delta_i) & (distances < 3 * delta_i)\n",
    "        scores[mask] = 0.6 - 0.58 * ((distances[mask] - delta_i) / (3 * delta_i - delta_i))\n",
    "        \n",
    "        return scores\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 모델 학습 및 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 평가 코드\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 성능 평가 함수\n",
    "def evaluate_fold(model, X_test, y_test):\n",
    "    similarity_scores = model.reconstruction_error(X_test)\n",
    "    threshold = 0.6  # 논문 기준 임계값\n",
    "    y_pred = (similarity_scores > threshold).astype(int)\n",
    "    y_test_numeric = y_test.map({'typical': 1, 'atypical': 0})\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_test_numeric, y_pred),\n",
    "        \"Precision\": precision_score(y_test_numeric, y_pred),\n",
    "        \"Recall\": recall_score(y_test_numeric, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test_numeric, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test_numeric, similarity_scores)\n",
    "    }\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# 파라미터 리스트 설정\n",
    "n_clusters_list = [5, 10, 20, 30, 40, 50]  # 클러스터 수 후보들\n",
    "n_classifiers_list = [25, 50, 100]  # 분류기 수 후보들\n",
    "subsample_ratio = 0.63  # 고정값\n",
    "\n",
    "# 파라미터 조합 생성\n",
    "parameter_combinations = list(product(n_classifiers_list, n_clusters_list))\n",
    "\n",
    "# 60초 간격 데이터 추출 함수\n",
    "def extract_60s_intervals(data, time_column=None):\n",
    "    \"\"\"\n",
    "    60초 간격 데이터를 추출하는 함수\n",
    "    Args:\n",
    "        data (DataFrame): 입력 데이터\n",
    "        time_column (str): 시간 기준 컬럼 (선택적)\n",
    "    Returns:\n",
    "        DataFrame: 60번째 간격으로 추출된 데이터\n",
    "    \"\"\"\n",
    "    if time_column:\n",
    "        data = data.sort_values(time_column)  # 시간 정렬\n",
    "    return data.iloc[::60, :]  # 60번째마다 데이터 추출\n",
    "\n",
    "# Five-Fold Cross Validation 학습 및 평가\n",
    "base_path = \"processeed_dataset/User1/FiveFoldCrossValidation\"\n",
    "results = []  # 결과 저장\n",
    "\n",
    "for n_classifiers, n_clusters in parameter_combinations:\n",
    "    print(f\"\\n### Training with n_classifiers={n_classifiers}, n_clusters={n_clusters} ###\")\n",
    "    fold_results = []\n",
    "\n",
    "    # 모델 학습 및 저장\n",
    "    for fold_id in range(1, 6):  # Fold1 ~ Fold5\n",
    "        print(f\"Processing Fold {fold_id}...\")\n",
    "        fold_path = f\"{base_path}/Fold{fold_id}\"\n",
    "        \n",
    "        # 데이터 로드\n",
    "        training_path = f\"{fold_path}/training.csv\"\n",
    "        training_data = pd.read_csv(training_path)\n",
    "        \n",
    "        # 60초 간격 데이터 추출\n",
    "        training_data_60s = extract_60s_intervals(training_data)\n",
    "        X_train = training_data_60s.drop(columns=['ANOM_COND'])\n",
    "        \n",
    "        # 모델 학습\n",
    "        model = OCKRA(n_classifiers=n_classifiers, n_clusters=n_clusters, subsample_ratio=subsample_ratio)\n",
    "        model.fit(X_train)\n",
    "        \n",
    "        # 모델 저장\n",
    "        model_save_path = f\"ockra_model_fold{fold_id}.pkl\"\n",
    "        joblib.dump(model, model_save_path)\n",
    "        print(f\"Model for Fold {fold_id} saved to {model_save_path}\")\n",
    "    \n",
    "    # 성능 평가\n",
    "    for fold_id in range(1, 6):  # Fold1 ~ Fold5\n",
    "        print(f\"Evaluating Fold {fold_id}...\")\n",
    "        fold_path = f\"{base_path}/Fold{fold_id}\"\n",
    "        \n",
    "        # 데이터 로드\n",
    "        testing_path = f\"{fold_path}/testing.csv\"\n",
    "        testing_data = pd.read_csv(testing_path)\n",
    "        \n",
    "        # 60초 간격 데이터 추출\n",
    "        testing_data_60s = extract_60s_intervals(testing_data)\n",
    "        X_test = testing_data_60s.drop(columns=['ANOM_COND'])\n",
    "        y_test = testing_data_60s['ANOM_COND']\n",
    "        \n",
    "        # 해당 폴드 모델 불러오기\n",
    "        model_load_path = f\"ockra_model_fold{fold_id}.pkl\"\n",
    "        model = joblib.load(model_load_path)\n",
    "        \n",
    "        # 성능 평가\n",
    "        fold_result = evaluate_fold(model, X_test, y_test)\n",
    "        fold_results.append(fold_result)\n",
    "        print(f\"Fold {fold_id} Results: {fold_result}\")\n",
    "\n",
    "    # 평균 결과 저장\n",
    "    fold_results_df = pd.DataFrame(fold_results)\n",
    "    avg_result = fold_results_df.mean()\n",
    "    avg_result['n_classifiers'] = n_classifiers\n",
    "    avg_result['n_clusters'] = n_clusters\n",
    "    results.append(avg_result)\n",
    "    print(f\"Average Results for n_classifiers={n_classifiers}, n_clusters={n_clusters}:\\n{avg_result}\")\n",
    "\n",
    "# 결과 DataFrame 생성 및 저장\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"parameter_search_results.csv\", index=False)\n",
    "print(\"\\nParameter search results saved to 'parameter_search_results.csv'.\")\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_clusters(data, n_clusters):\n",
    "    \"\"\"\n",
    "    K-means++로 클러스터링 결과와 중심점을 시각화하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): 입력 데이터 (2개의 주요 특징만 선택)\n",
    "        n_clusters (int): 클러스터 수\n",
    "    \"\"\"\n",
    "    # K-means++ 클러스터링 수행\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "    kmeans.fit(data)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    # 클러스터 시각화\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_data = data[labels == cluster_id]\n",
    "        plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {cluster_id}', alpha=0.6)\n",
    "    \n",
    "    # 클러스터 중심 시각화\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], s=200, c='red', marker='X', label='Centroids')\n",
    "    plt.title(f'K-means++ Clustering with {n_clusters} Clusters', fontsize=16)\n",
    "    plt.xlabel('Feature 1', fontsize=14)\n",
    "    plt.ylabel('Feature 2', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 데이터 로드 (예시로 Fold1의 데이터를 사용)\n",
    "training_path = \"processeed_dataset/User1/FiveFoldCrossValidation/Fold1/training.csv\"\n",
    "training_data = pd.read_csv(training_path)\n",
    "\n",
    "# 주요 2개 특징 선택 (예시로 첫 번째, 두 번째 열 사용)\n",
    "X_train = training_data.drop(columns=['ANOM_COND']).iloc[:, :2].values\n",
    "\n",
    "# 클러스터 시각화 (예: 클러스터 수 5)\n",
    "visualize_clusters(X_train, n_clusters=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Friedman Test Results for n_classifiers:\n",
      "Test Statistic: 1.0, p-value: 0.6065306597126334\n",
      "\n",
      "Friedman Test Results for n_clusters:\n",
      "Test Statistic: 10.80952380952381, p-value: 0.055290127801493866\n",
      "\n",
      "n_classifiers에 따른 AUC 값 간에 통계적으로 유의미한 차이가 없습니다.\n",
      "n_clusters에 따른 AUC 값 간에 통계적으로 유의미한 차이가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('parameter_search_results.csv')\n",
    "\n",
    "# n_classifiers와 n_clusters 각각에 대한 그룹 생성 (AUC대상)\n",
    "classifiers_groups = data.groupby('n_classifiers')['AUC'].apply(list)\n",
    "clusters_groups = data.groupby('n_clusters')['AUC'].apply(list)\n",
    "\n",
    "# Friedman Test 수행\n",
    "stat_classifiers, p_classifiers = friedmanchisquare(*classifiers_groups)\n",
    "stat_clusters, p_clusters = friedmanchisquare(*clusters_groups)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nFriedman Test Results for n_classifiers:\")\n",
    "print(f\"Test Statistic: {stat_classifiers}, p-value: {p_classifiers}\")\n",
    "\n",
    "print(\"\\nFriedman Test Results for n_clusters:\")\n",
    "print(f\"Test Statistic: {stat_clusters}, p-value: {p_clusters}\\n\")\n",
    "\n",
    "# p-value 해석\n",
    "if p_classifiers < 0.05:\n",
    "    print(\"n_classifiers에 따른 AUC 값 간에 통계적으로 유의미한 차이가 있습니다.\")\n",
    "else:\n",
    "    print(\"n_classifiers에 따른 AUC 값 간에 통계적으로 유의미한 차이가 없습니다.\")\n",
    "\n",
    "if p_clusters < 0.05:\n",
    "    print(\"n_clusters에 따른 AUC 값 간에 통계적으로 유의미한 차이가 있습니다.\")\n",
    "else:\n",
    "    print(\"n_clusters에 따른 AUC 값 간에 통계적으로 유의미한 차이가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test statistic: 30.78873239436617\n",
      "P-value: 2.062109429491706e-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# CSV 파일 로드\n",
    "data = pd.read_csv('parameter_search_results.csv')\n",
    "\n",
    "# 필요한 열 추출\n",
    "auc = data['AUC']\n",
    "n_classifiers = data['n_classifiers']\n",
    "n_clusters = data['n_clusters']\n",
    "\n",
    "# 프리드만 검정 수행\n",
    "stat, p = friedmanchisquare(auc, n_classifiers, n_clusters)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Friedman test statistic: {stat}\")\n",
    "print(f\"P-value: {p}\")\n",
    "\n",
    "# if p < 0.05:\n",
    "#     #print(\"유의미한 차이가 있습니다.\")\n",
    "# else:\n",
    "#     #print(\"유의미한 차이가 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
